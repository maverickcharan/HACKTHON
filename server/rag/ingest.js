import { Chroma } from "@langchain/community/vectorstores/chroma";
import { OllamaEmbeddings } from "@langchain/ollama";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

console.log("ðŸš€ Ingest started...");

const data = JSON.parse(
  fs.readFileSync(new URL("./data.json", import.meta.url), "utf8")
);

const embeddings = new OllamaEmbeddings({
  model: "nomic-embed-text"
});

const BATCH_SIZE = 50;

// ---- FIRST BATCH ----
const firstBatch = data.slice(0, BATCH_SIZE).map(item => ({
  pageContent: `${item.title}. ${item.description}. Mood:${item.mood}. Language:${item.language}. Category:${item.category}`,
  metadata: item
}));

console.log("ðŸ“¦ Creating collection with first batch...");
console.log(`ðŸ’¾ Persisting to: ${path.resolve(__dirname, "chroma")}`);

const vectorStore = await Chroma.fromDocuments(
  firstBatch,
  embeddings,
  {
    collectionName: "content-db-v2",
    persistDirectory: path.resolve(__dirname, "chroma")
  }
);

// ---- REMAINING BATCHES ----
for (let i = BATCH_SIZE; i < data.length; i += BATCH_SIZE) {
  const batch = data.slice(i, i + BATCH_SIZE).map(item => ({
    pageContent: `${item.title}. ${item.description}. Mood:${item.mood}. Language:${item.language}. Category:${item.category}`,
    metadata: item
  }));

  console.log(`ðŸ“¦ Processing batch ${i / BATCH_SIZE + 1}`);

  await vectorStore.addDocuments(batch);
}

console.log("âœ… Data stored in Vector DB successfully");
